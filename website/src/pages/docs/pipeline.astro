---
import DocsLayout from '../../layouts/DocsLayout.astro'

const toc = [
  { label: 'Quick mode', anchor: 'quick-mode' },
  { label: 'Manual mode', anchor: 'manual-mode' },
  { label: 'The seven steps', anchor: 'steps' },
  { label: 'Severity levels', anchor: 'severity' },
]
---

<DocsLayout title="Review Pipeline" toc={toc} icon={`<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="1.75"><path stroke-linecap="round" stroke-linejoin="round" d="M13 10V3L4 14h7v7l9-11h-7z" /></svg>`}>
  <p>
    PR Review Kit provides two ways to run a review: quick mode for a fully automated pipeline, and
    manual mode for step-by-step control.
  </p>

  <h2 id="quick-mode">Quick mode</h2>
  <p>
    Quick mode runs the full pipeline in one command. It pauses only once to ask which PR or branch to
    review, then handles everything else automatically.
  </p>
  <p>Start it from your AI IDE:</p>
  <pre><code>/prr-quick</code></pre>
  <p>The pipeline runs in order: select PR, describe changes, collect context, run all reviewers, generate report. Inline comments are posted if your platform is configured.</p>

  <h2 id="manual-mode">Manual mode</h2>
  <p>
    Manual mode gives you full control. Start the master agent and pick each step from the menu:
  </p>
  <pre><code>/prr-master</code></pre>
  <p>From the menu, you can run any step individually, re-run a specific reviewer, or skip steps you do not need.</p>

  <h2 id="steps">The seven steps</h2>

  <h3>1. Select PR</h3>
  <p>
    Lists open PRs from your platform (GitHub, GitLab, Azure DevOps, or Bitbucket) or lets you
    select branches manually. Enter the PR number and the diff is loaded directly into AI context.
  </p>

  <h3>2. Describe changes</h3>
  <p>
    Classifies the PR type (feature, fix, refactor, etc.), generates a concise summary, and produces
    a file-by-file walkthrough of all changes.
  </p>

  <h3>3. Collect context (automatic)</h3>
  <p>
    Runs automatically after step 2. Analyzes the changed files to detect relevant domains, reads
    project config files and standards documents, extracts inline annotations from the diff, and
    optionally queries MCP tools or RAG systems. The result is saved as a context file loaded by
    all reviewer agents.
  </p>

  <h3>4. Deep code review</h3>
  <p>
    Runs all specialist reviewer agents — General, Security, Performance, Architecture, and Business
    Review — either in parallel or in sequence. Each agent uses the fresh context collected in step 3.
    See <a href="/docs/reviewers">Reviewer Agents</a> for details on what each one checks.
  </p>

  <h3>5. Generate report</h3>
  <p>
    Compiles all findings from every reviewer into a single Markdown report. Findings are sorted by
    severity from blockers to suggestions. The report is saved to your configured output path.
  </p>

  <h3>6. Post inline comments</h3>
  <p>
    Optionally posts findings as inline code comments on the exact file and line in your platform PR.
    Requires <code>platform_repo</code> to be configured and the relevant platform CLI to be
    authenticated.
  </p>

  <h2 id="severity">Severity levels</h2>
  <p>All findings use a consistent four-level severity scale:</p>
  <table>
    <thead>
      <tr><th>Level</th><th>Meaning</th></tr>
    </thead>
    <tbody>
      <tr>
        <td><strong>Blocker</strong></td>
        <td>Must be fixed before the PR can be merged</td>
      </tr>
      <tr>
        <td><strong>Warning</strong></td>
        <td>Should be fixed, with an explanation of the risk</td>
      </tr>
      <tr>
        <td><strong>Suggestion</strong></td>
        <td>Nice-to-have improvement, not blocking</td>
      </tr>
      <tr>
        <td><strong>Question</strong></td>
        <td>Needs clarification from the PR author</td>
      </tr>
    </tbody>
  </table>
</DocsLayout>
