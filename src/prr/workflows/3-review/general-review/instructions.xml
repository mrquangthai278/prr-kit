<workflow>
  <critical>Workflow engine rules: {project-root}/_prr/core/tasks/workflow.xml</critical>
  <critical>Communicate all responses in {communication_language}</critical>
  <critical>Load PR context from {pr_context} before starting review</critical>
  <critical>Every finding MUST include: file path + line/function reference + severity + suggested fix</critical>
  <critical>Finding severities: ğŸ”´ BLOCKER (must fix before merge) | ğŸŸ¡ WARNING (should fix) | ğŸŸ¢ SUGGESTION (nice to have) | â“ QUESTION (uncertain â€” ask author before judging). Use â“ when: (a) you cannot determine intent from the diff alone, (b) behavior depends on runtime context you can't see, (c) a side effect MAY exist but you need confirmation. A QUESTION that gets a bad answer becomes a BLOCKER or WARNING.</critical>

  <step n="1" goal="Load PR context, knowledge base, and diff">
    <check if="{pr_context} does not exist">
      <output>âŒ No PR selected. Please run [SP] Select PR first.</output>
      <stop/>
    </check>

    <action>Read {pr_context} to get: target_branch, base_branch, diff_strategy, files_changed, pr_knowledge_base</action>
    <action>Load PR-specific knowledge base from {pr_knowledge_base} (e.g., pr-123-context.yaml)</action>
    <note>Knowledge base contains: relevant ESLint rules, guidelines from CLAUDE.md/CONTRIBUTING.md/ARCHITECTURE.md, inline annotations, external rules</note>
    <action>Run: git diff {base_branch}...{target_branch} in {target_repo}</action>
    <action>Note diff_strategy: if 'chunked', process file by file</action>

    <output>ğŸ” Starting General Code Review
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
PR: {target_branch} â†’ {base_branch}
Context: Loaded fresh PR-specific knowledge base
Strategy: {diff_strategy}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</output>
  </step>

  <step n="2" goal="Review code logic and correctness with PR-specific context">
    <action>Apply ESLint rules from knowledge_base.relevant_rules.eslint</action>
    <action>Apply guidelines from knowledge_base.relevant_guidelines</action>
    <action>Check inline annotations from knowledge_base.inline_context</action>
    <action>For each changed file (or chunk if diff_strategy=chunked):</action>
    <check-list id="logic">
      <item>Logical errors: conditions, edge cases, off-by-one errors</item>
      <item>Null/undefined handling: are all possible null states handled?</item>
      <item>Error handling: are errors caught and handled appropriately?</item>
      <item>Return values: are return paths complete and correct?</item>
      <item>Data validation: is user input properly validated?</item>
    </check-list>
    <output-format>
For each finding:
ğŸ”´/ğŸŸ¡/ğŸŸ¢/â“ [SEVERITY] `path/to/file:lineN` â€” **Description**
â†’ Suggested fix or question: `code example or specific question to ask author`
    </output-format>
  </step>

  <step n="3" goal="Review code quality and maintainability">
    <check-list id="quality">
      <item>Naming: are variable/function/class names clear and meaningful?</item>
      <item>Function size: are functions doing one thing? (>30 lines is a yellow flag)</item>
      <item>DRY violations: is logic duplicated that should be extracted?</item>
      <item>Magic numbers/strings: should be named constants</item>
      <item>Comments: missing where logic is complex; unnecessary where code is clear</item>
      <item>Dead code: unreachable code, unused variables, TODO comments left</item>
    </check-list>
  </step>

  <step n="4" goal="Review test coverage">
    <check-list id="tests">
      <item>New logic: is it covered by unit tests?</item>
      <item>Edge cases: are boundary conditions tested?</item>
      <item>Error paths: are error/exception paths tested?</item>
      <item>Test quality: do tests actually test behavior, not just coverage?</item>
    </check-list>
  </step>

  <step n="5" goal="Review side effects and cross-file technical impact">
    <note>Reference the Impact Map from the describe-pr walkthrough if available. If not, perform the scan inline. This step applies to all stacks â€” frontend, backend, mobile, gaming, etc.</note>
    <check-list id="side-effects">
      <item>Observer / reactive subscriptions: are all dependencies or triggers for observers, watchers, and subscriptions declared correctly? Missing deps cause stale state; unnecessary triggers cause redundant work. Use â“ if intent is unclear.</item>
      <item>Resource cleanup: are resources acquired in lifecycle hooks (subscriptions, timers, handles, connections, threads, listeners) properly released on teardown/destruction? Missing cleanup causes leaks.</item>
      <item>Derived / computed values: do any derived values or selectors have hidden side effects (mutations, I/O, network calls)? Derived values must be pure.</item>
      <item>Shared / global state mutations: does this change mutate state visible outside the current module (singletons, global variables, shared memory, context, state managers)? Cross-reference Impact Map for who observes it.</item>
      <item>Event / signal dispatch: new events, signals, notifications, or messages emitted â€” are all consumers/listeners accounted for? Is the payload shape backward compatible?</item>
      <item>Public interface changes on shared modules: flag any breaking change (signature, return type, exported contract) here as â“ QUESTION or ğŸ”´ BLOCKER. Full blast radius analysis is covered in Architecture Review â€” cross-reference if AR has already run.</item>
      <item>Unintended cascading reactions: does a state or data change trigger downstream observers, callbacks, or re-computations in unrelated parts of the system? Check for missing guards, debounce, or memoization.</item>
      <item>Cross-boundary contract changes: changed API response, schema, binary format, serialization format, or protocol â€” are all consumers (other services, clients, upstream/downstream systems) updated in this PR or is a migration plan documented?</item>
    </check-list>
    <output-format>
For side effect findings, include the AFFECTED LOCATION (the file outside the diff that is impacted):
â“ QUESTION `src/core/SessionManager.cpp:42` â€” `activeUser` data structure changed. Are all observers updated?
   Potentially affected: ProfileRenderer.cpp (callback on activeUser), PermissionGuard.ts (derived from activeUser)
   â†’ Ask author: "Were ProfileRenderer and PermissionGuard tested with the new data shape?"

ğŸ”´ BLOCKER `src/common/InputHandler.h:15` â€” Required parameter `deviceId` added without default. Breaking change.
   Affected consumers: ~12 files (see Impact Map)
   â†’ Add default value or make optional; audit all call sites.
    </output-format>
  </step>

  <step n="6" goal="Compile and write findings">
    <action>Group all findings by severity: ğŸ”´ Blockers first, then ğŸŸ¡ Warnings, then ğŸŸ¢ Suggestions, then â“ Questions</action>
    <action>Add positive observations: acknowledge good practices found</action>
    <action>Write findings to {output_file} using the standard review report format</action>
    <action>Update {pr_context}: add 'general-review' to completed reviews list</action>
    <output>âœ… General review complete. {blocker_count} blockers, {warning_count} warnings, {suggestion_count} suggestions, {question_count} questions for author.
Run [RR] Generate Report to compile all findings, or continue with another review type.</output>
  </step>
</workflow>
